<BODY BGCOLOR="#EAEAEA">

    <TITLE>Cognitive Neuroscience Society Meeting 2008 Symposium</TITLE> 

<h3>
Symposium at the
<a href="http://www.cnsmeeting.org/symposia.htm">
Cognitive Neuroscience Society Meeting, 2008.</a>
</h3>

Hyatt Regency, San Francisco. <br>
Sunday, April 13, 2008, 10:00am - 12:00pm. 
<br>
<br>
<b> Symposium title: </b>
Pattern-based fMRI analyses as a route to revealing neural representations
<br>
<br>
<b> Chair:</b> Rajeev Raizada 
<br>
<b> Speakers:</b> 
<a href="http://weblamp.princeton.edu/~psych/psychology/research/haxby/index.php">
Jim Haxby</a>, 
<a href="http://fim.nimh.nih.gov/user/6">
Nikolaus Kriegeskorte</a>, 
<a href="http://faculty.washington.edu/raizada/">
Rajeev Raizada</a>,
<a href="http://faculty.washington.edu/gboynton/">
Geoff Boynton</a>.
<br>
<br>

<b> Symposium theme:</b> Within any active brain region, many neural
representations are intermingled. Because these representations are
spatially colocalised, they may elicit the same levels of local average
activation, with the result that neuroimaging studies have difficulty
telling them apart. Recent studies analysing multi-voxel spatial
patterns of fMRI activity are starting to provide new methods for
accessing such neural representations, and for relating them to
behaviour. This symposium presents examples of such research, from
diverse cognitive domains. Jim Haxby will describe how pattern-based
analyses reveal distributed representations of objects in visual cortex.
Drawing parallels between human and monkey studies, Nikolaus
Kriegeskorte will show how information-based fMRI can reveal the
structure of categorical representations of faces and objects in
inferotemporal cortex. In the domain of speech perception, Rajeev
Raizada will show how the distinctness of phonetic representations in
the brain can predict people's ability to hear non-native speech
contrasts. Moving beyond stimulus-driven neural responses, Geoff Boynton
will describe how feature-based attentional signals can be decoded from
distributed cortical activity.

<br>
<br>
<b><u>Jim Haxby:
Distributed neural representation of faces and objects in ventral
temporal cortex</u></b>
<br>
Functional brain imaging has revealed a complex, macroscopic
organization in the functional architecture of the ventral object vision
pathway. Numerous studies have found regions of ventral temporal cortex
that consistently demonstrate category-related response preferences,
most notably a region that responds maximally during face perception,
the fusiform face area (FFA). Faces and numerous other object
categories, however, also evoke distinct patterns of response across
wider expanses of ventral temporal cortex, including distinct patterns
of response in cortical regions that respond submaximally to the
category being viewed, suggesting that the representations of faces and
other objects extend beyond the regions defined by category preference.
Methods for analyzing these patterns of response, which we call
multi-voxel pattern analysis, represent a major departure from previous,
standard methods for analyzing functional neuroimaging data. Whereas
previous methods were designed to find clusters of voxels with similar
response properties, topographic pattern analysis is designed to detect
reliable patterns of differences among the responses of voxels. The
information-carrying capacity of submaximal responses suggests that
these patterns may reflect spatially distributed population responses in
which both strong and weak responses play an integral role in the
representation of complex percepts. Furthermore, the similarity of
patterns of response to visual stimuli is correlated with psychological
similarity, suggesting that these methods now allow us to use fMRI to
investigate how neural representations of visual stimuli are structured.
<br>
<br>
<b><u>Nikolaus Kriegeskorte:
Exploiting hi-res fMRI and relating measurement modalities with
representational similarity analysis</u></b>
<br>
High-resolution functional magnetic resonance imaging (hi-res fMRI)
promises to help bridge the gap of spatial scales between human
low-resolution neuroimaging and animal invasive electrophysiology. I
will discuss how the fine-scale neuronal-pattern information present in
hi-res fMRI data can be exploited for neuroscientific insight by means
of multivariate analysis. In particular, I will focus on the novel
approach of "representational similarity analysis", which allows us (1)
to combine evidence across brain space and experimental conditions to
sensitively detect neuronal pattern information and (2) to relate
results (a) between different modalities of brain-activity measurement,
(b) between different species, and (c) between brain-activity data and
computational models of brain information processing. I will illustrate
this approach with a study combining human and monkey data from hi-res
fMRI and single-cell recordings, respectively. We investigated response
patterns elicited by the same 92 photographs of isolated natural objects
in inferotemporal (IT) cortex of both species. Within each species, we
compute a matrix of response-pattern similarities (one similarity value
for each pair of images). We find a striking match of the resulting
similarity matrices for man and monkey. This finding suggests very
similar categorical IT representations and provides some hope that data
from single-cell recording and fMRI, for all their differences, may
consistently reveal neuronal representations when subjected to massively
multivariate analyses of response-pattern information.
<br>
<br>
<b><u>Rajeev Raizada:
Predicting individual differences in speech perception using
pattern-based fMRI analysis of phonemic representations</u></b>
<br>
The brain's ability to discriminate stimuli depends on how fine-grained
its stimulus representations are. This representational granularity can
vary across individuals, as a function of factors such as sensory
environment and learning history. A key goal of cognitive neuroscience
has been to relate the properties of such representations in
individuals' brains to their levels of behavioural performance. However,
because the neural representations of different but related stimuli are
typically colocalised within the same brain area, their distinctness
from each other has been difficult for fMRI to measure. This problem has
been overcome in low-level sensory cortices, where the representational
grain can be calculated from well-defined spatiotopic maps, or from
direct mappings between stimulus-energy and levels of neural activation.
However, for all but the simplest stimuli, no such mappings are
available. For example, different phonemes such as /ra/ and /la/
activate the same areas of cortex, but there is no known "phonotopic
map" that might allow the distinctness of the evoked neural
representations to be measured. I will describe how, by analysing the
multi-voxel spatial fMRI patterns elicited by these stimuli in English
and Japanese speakers, the statistical separability of such neural
representations can be directly quantified. Moreover, in right primary
auditory cortex, the separability of these fMRI patterns strongly
predicted the degree to which subjects could behaviourally discriminate
the stimuli that gave rise to them. This opens up a new method, which
may have broad applicability, for relating neural representations in the
human brain to levels of behavioural performance, and also reveals a
hitherto unknown role played by right auditory cortex in processing
speech.
<br>
<br>
<b><u>Geoff Boynton:
Pattern-based decoding of feature-specific visual attention</b></u>
<br>
When faced with a crowded visual scene, observers must selectively
attend to behaviorally relevant objects to avoid sensory overload. Often
this selection process is guided by prior knowledge of a target-defining
feature (e.g., the color red when looking for an apple), which enhances
the firing rate of visual neurons that are selective for the attended
feature. Here, we used functional magnetic resonance imaging and a
pattern classification algorithm to predict the attentional state of
human observers as they monitored a visual feature (one of two
directions of motion). We find that feature-specific attention effects
spread across the visual field - even to regions of the scene that do
not contain a stimulus. This spread of feature-based attention to empty
regions of space may facilitate the perception of behaviorally relevant
stimuli by increasing sensitivity to attended features at all locations
in the visual field.

