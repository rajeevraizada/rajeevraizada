{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQ7gJOYTNAZa"
   },
   "source": [
    "## Tutorial on the basics of convolving with a haemodynamic response function (HRF), using Python.\n",
    "\n",
    "Written by Rajeev Raizada: rajeev dot raizada at gmail dot com\n",
    " \n",
    "There is also a follow-up file about the structure of an fMRI-analysis design\n",
    "matrix: design_matrix_tutorial.ipynb\n",
    "\n",
    "Neither file assumes any prior knowledge of linear algebra.\n",
    "\n",
    "This is a live Jupyter notebook, running on the Google Colab server (for free!). So, you can run the code, make changes to it, and see what happens. A good exercise is to change the onset times of the stimuli, and see what that does to the predicted voxel responses and how they combine with each other.\n",
    "\n",
    "You can run each code cell by clicking on the [ ] part to its left. When you mouse-over this, it will turn into an arrow, meaning \"Run\". Click on that arrow to run that cell. \n",
    "\n",
    "You can also run each cell in this, or any other, Jupyter notebook by clicking inside it and hitting the \"Shift\"+\"Enter\" keys together.\n",
    "\n",
    "The easiest way to run all the cells in one go is to click on the \"Runtime\" menu at the top of this page, and hit \"Run all\".\n",
    "\n",
    "## The key points\n",
    "\n",
    "1. The brain produces a fairly fixed, stereotyped blood flow response every time a stimulus hits it. That's the HRF (haemodynamic response function).\n",
    "\n",
    "2. Once one of these resonses starts, it just does its thing until it has finished. i.e. it peaks, it goes back down to zero, it undershoots  a bit, then it settles back to baseline. All this was kicked off as a a result of the stimulus coming in, and it will run to completion regardless of what stimuli, if any, come in later. (This is just an approximation of what really happens in the brain, of  course, but it turns out that it isn't all that far from being\n",
    "true).\n",
    "\n",
    "3. What we just described is exactly what the process called \"convolution\" is. To convolve, you need two things. First, you need an \"impulse  response function\" (IRF), i.e. the chain of events that will be started  off every time an \"impulse\" happens, e.g. the brain sees a stimulus. And in the brain, the response to each impulse is the haemodynamic response function --- the HRF. Every time a stimulus comes in, one of these HRFs gets started off, and then it runs it course (peak,  undershoot, baseline) over the next 16 seconds or so.\n",
    "\n",
    "Second, you need a vector to be convolved with that impulse response function. A vector is just a bunch of numbers in a row. In this case, our vector to be convolved is a list of whether a stimulus is shown or not, at each moment in time. So, we have a bunch of numbers lined up in a row, with time being represented by our position  along the row.  This type of vector is often referred to as a time-series.\n",
    "\n",
    "In this case, the time-series is describing whether a stimulus is being shown at that moment in time or not. If there's no stimulus, we put a zero. If there is a stimulus, we put a 1. The first number is what is happening at time t=0,  the second number is what is happening at t=1 etc.\n",
    "\n",
    "Here's a key point: every stimulus will kick off its own HRF, and so it can often happen that the previous stimulus's HRF hasn't finished by the time the next stimulus, with its new HRF comes in. So, the two HRFs will overlap in time.\n",
    "\n",
    "In convolution, if you get different impulse response functions  overlapping in time, you can work out what the total response at that moment in time will be simply by adding up the individual  responses.\n",
    "\n",
    "To say that you can get the total response just by adding up the individual overlapping responses is exactly what it means to say that the system is **linear**. If something is linear, then its  total response to separate inputs is just the sum of what its individual responses would have been to the individual inputs.\n",
    "\n",
    "Does the brain do this? Does it just \"add up\" blood flow responses which are overlapping?\n",
    "\n",
    "**Yes!** (to a reasonable approximation). And that is why convolution does a reasonable job of describing what the brain does.\n",
    "\n",
    "To see more detail about the math of convolution, look at the companion program math_of_convolution.ipynb\n",
    "\n",
    "4. In fMRI, the data that we get for each voxel is the blood oxygenation at that voxel at each point in time. We also know what the presentation times of our stimuli were. So, what any fMRI-analysis program does is this: It takes the time series of stimulus onsets, and convolves it with the HRF. This gives a **prediction** of the blood flow response that we should get a given voxel, if that voxel is responding to the stimuli.\n",
    "\n",
    "Then, we take that prediction, and go and compare it against the measured data. And we see how well they match.\n",
    "\n",
    "First let's create a made-up vector that looks like an HRF. A vector is just a bunch of numbers in a row. In Python, we make a vector by putting the row of numbers inside square brackets [  ]\n",
    "\n",
    "Give one value for each 1-second time point. So, the 18 numbers in the vector below correspond to the values of the HRF from time=0 to time=18.\n",
    "\n",
    "Note that the important thing about the HRF here is  just the overall **shape** that it has, not the exact values of the numbers. So, it doesn't mean anything that the max value in the numbers below is 9, or 9.2 or whatever. It's the shape of the HRF curve over time that matters.\n",
    "\n",
    "(Actually, this isn't completely true.  For some math-related purposes it turns out that it's convenient to have the HRF sum to 1, and this is what SPM does.  But it would be a distraction to worry about that right now. Let's just define an HRF with the right overall shape, and plot it.)\n",
    "\n",
    "First, we import the Python modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgR52vvzO50G"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# This next line just makes the fonts bigger. Their default size is too small\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgR8S8NgPP2y"
   },
   "source": [
    "Now let's create a vector that has the overall shape of a real HRF. We are going to make a NumPy array, which is just like a normal list, except that you can do math with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4UNAFNAPPEp"
   },
   "outputs": [],
   "source": [
    "hrf = np.array([ 0, 0, 1, 5, 8, 9.2, 9, 7, 4, 2, 0, -1, -1, -0.8, -0.7, -0.5, -0.3, -0.1, 0, 0 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdcrwih-PbMx"
   },
   "source": [
    "Let's plot it. For that, we need to make a vector of time-values to use as the x-coordinates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsOcro4bPr0q"
   },
   "outputs": [],
   "source": [
    "time_vector = range(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1t3hdruPzyZ"
   },
   "source": [
    "Now we will plot the HRF against time, with time_vector as the x-coordinates, hrf as the\n",
    "y-coordinates, and with the line style being a solid line with circles on it. The way to specify \"solid line with circles on it\" is to make the third argument be 'o-'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1569335714933,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "VCEtK4U3Pc4j",
    "outputId": "cd2e896d-9510-4cb5-ea13-a4b7b0a6a0d3"
   },
   "outputs": [],
   "source": [
    "plt.plot(time_vector,hrf,'o-')  \n",
    "                            \n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.title('The typical shape of an HRF') \n",
    "plt.grid(color='k',linestyle=':')     # Overlay a dotted-line grid on top of the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ax6gDpSUT24I"
   },
   "source": [
    "Now let's make a vector of that is the time-series of our stimulus onsets, so that we can convolve that vector with the HRF, as described in the intro above.\n",
    "\n",
    "A vector is just a bunch of numbers in a row. In this case, they are lined up in time. i.e. the first number is what is happening at time t=0, the second number is what is happening at t=1 etc. Our vector to be convolved is a list of whether a stimulus is shown or not, at each moment in time. If there's no stimulus, we put a zero. If there is a stimulus, we put a 1.\n",
    "\n",
    "Suppose that our scan lasts 60 seconds, and that we use a visual stimulus: we flash a light at time t=10.\n",
    "\n",
    "Let's make an stimulus-time-series vector that has one element for each second of time. Then the vector for that light stimulus will have a 1 in the 10th position, meaning t=10, and will be zeros everywhere else.\n",
    "\n",
    "So, it's 9 zeros, then a 1, then 50 more zeros, making the vector have 60 entries altogether, for the 60 second scan.\n",
    "\n",
    "Note that by just putting a single 1 to represent the flash of light, we are saying that the flash happened suddenly, just at that moment of time, i.e. it was an event, as opposed to a block (also called an \"epoch\"), in which the stimuli are spread out over a longer period of time. E.g. a stimulus-block might last twenty seconds, rather than an event, which happens at a single moment.\n",
    "\n",
    "This sudden flash of light will spark off a sudden neural event, in this case a sudden burst of neural firing in visual cortex.\n",
    "\n",
    "In Python, we can make n zeros in a row, like this: [0] * n\n",
    "\n",
    "Note that Python starts counting at zero, not at one. (Matlab and Julia start counting at 1). So, to put a 1 at t=10, we actually need to put that 1 in the 11th position, so that it has 10 preceding zeros in the positions 0,1,2,...,9\n",
    "\n",
    "To make the whole big vector with 10 zeros, a single 1, and then 50 zeros, we can just put the separate vectors next to each other in a row, and then concatenate them using the + sign, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZEHqs7YT4Vy"
   },
   "outputs": [],
   "source": [
    "first_light_stim_time_series = [0]*10 + [1] + [0]*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOLP_sflm_qh"
   },
   "source": [
    "We are going to do math with this time-series and the others below (not much math, just adding and convolving), so we will convert from lists to NumPy arrays, by wrapping np.array() around them.\n",
    "\n",
    "Notice that we used the + sign above to concatenate some lists. So, the + sign didn't actually add the elements of the lists, it just joined them all together. Below, we are going to do elementwise addition, so we'll want + to actually mean \"perform addition\". For that, we need to convert the lists into NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzxDcOfXnUJe"
   },
   "outputs": [],
   "source": [
    "first_light_stim_time_series = np.array([0]*10 + [1] + [0]*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUkCWDyVUMBY"
   },
   "source": [
    "Let's display this on the screen, using the print() function.\n",
    "\n",
    "First we show the name of the variable, by putting single quotes around its name, to tell Python that it is a string. Then we start a new line by printing the special character '\\n', which is the symbol for \"newline\". Then we print out the actual value of the variable, simply by passing it as the next input to print(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1540,
     "status": "ok",
     "timestamp": 1569335715058,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "AL8xp4dMUgHb",
    "outputId": "c698c064-e10f-4387-f2d2-a6657faf384d"
   },
   "outputs": [],
   "source": [
    "print('first_light_stim_time_series','\\n',first_light_stim_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqDX4elEUiEH"
   },
   "source": [
    "## Translation-guide\n",
    "\n",
    "Here we have made a time-series whether for every time-point (t=0, t=1, etc.) we are explicitly saying whether or not a stimulus is being shown. In this case, the light is shown at t=10, so put a 1 as the 10th element, and for the rest of the time no lights are shown, so we put 0 everywhere else.\n",
    "\n",
    "However, when using an fMRI-analysis package, people typically don't explicity make the whole time-series. They simply tell the package what the onset-times of the stimuli are, and let the package build the time-series of 0's and 1's on its own.\n",
    "\n",
    "So, for the case where we have a single light stimulus at t=10, the info entered into the analysis package would be something like:\n",
    "\n",
    "onset_times = [ 10 ]\n",
    "\n",
    "Similarly, if we flashed one light at t=10 and another at t=30, then we'd enter: \\\n",
    "onset_times = [ 10, 30 ]\n",
    "\n",
    "In this tutorial, and also in design_matrix_tutorial, we're going to explicitly make the stimulus-time-series vectors, rather than only supplying the onset-times, because these time-series vectors are the things that actually get convolved with the HRF. In an fMRI-analysis package, these time-series vectors would get made and convolved \"behind the scenes\", but we want to see everything in full view!\n",
    "\n",
    "Now that we have the stimulus-time-series vector and the HRF vector, we can convolve them. In Python, the command to convolve two vectors is a part of the NumPy module, conveniently called \"convolve\". As is standardly done, we imported NumPy at the beginning of the script and gave it the abbreviated name \"np\", so the convolution command is np.convolve()\n",
    "\n",
    "So, to convolve the time-series with the HRF, we do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C7n6YxyZVO3s"
   },
   "outputs": [],
   "source": [
    "hrf_convolved_with_stim_time_series = np.convolve(first_light_stim_time_series,hrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zjMl7yqVUim"
   },
   "source": [
    "Let's print that output as text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1498,
     "status": "ok",
     "timestamp": 1569335715061,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "TnDvxtDBVYaf",
    "outputId": "601519ad-a5ab-49ec-982f-abb6b8350d2e"
   },
   "outputs": [],
   "source": [
    "print('hrf_convolved_with_stim_time_series','\\n',hrf_convolved_with_stim_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5coLoFnVgBJ"
   },
   "source": [
    "Now let's plot it, using the Matplotlib PyPlot module, which we imported using the abbreviation \"plt\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2036,
     "status": "ok",
     "timestamp": 1569335715628,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "z1IeUCWmVrHd",
    "outputId": "6b36a16b-7a08-4cff-b192-e5e0b717bb45"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(2,1,1) # This is just to make the plots line up prettily \n",
    "                   # The first number is how many rows of subplots we have: 2 \n",
    "                   # The second number is how many columns: 1 \n",
    "                   # The third number is which subplot to draw in: the first one\n",
    "                   # So, we end up with two plots stacked on top of each other,\n",
    "                   # and we draw in the first one (which is the upper subplot)\n",
    "\n",
    "# Show when the stimulus is presented. We're using the\n",
    "# command \"stem\" to plot here, instead of the more standard command \"plot\". \n",
    "# \"Stem\" makes a nice looking plot with lines and circles. \n",
    "# This type of plot is good for showing discrete events, \n",
    "# such as stimulus onsets.\n",
    "plt.stem(first_light_stim_time_series,label='Time-series of light stim') \n",
    "                    # The label-string will show up in the figure legend\n",
    "\n",
    "plt.grid(color='k',linestyle=':') # Overlay a black dotted-line grid on top of the plot\n",
    "                    # The letter 'k' is used for black, because 'b' is blue!\n",
    "\n",
    "plt.legend()        # Make a legend to say what the plot-lines are showing\n",
    "\n",
    "plt.axis([0, 60, 0, 1.2]) # This just sets the display graph axis size \n",
    "                          # The first two numbers are the x-axis range: 0 to 60\n",
    "                          # The last two numbers are the y-axis range: 0 to 1.2 \n",
    "      \n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Stimulus present / absent');\n",
    "\n",
    "plt.subplot(2,1,2)        # Draw in the second subplot (the lower one)\n",
    "\n",
    "# With my super-long (but thereby clear, hopefully !) variable names,\n",
    "# this next command is a bit long. So, we'll split it across two lines\n",
    "# by using the \\ symbol, which tells Python that the command continues\n",
    "# across a line break. Without that \\, a line break starts a new command.\n",
    "plt.plot(hrf_convolved_with_stim_time_series,'rx-', \\\n",
    "         label='Stimulus time-series convolved with HRF')\n",
    "        # The argument 'rx-' means: Draw in red (r), \n",
    "        # use cross-shaped markers (x), \n",
    "        # and join them with a solid line (-) grid on\n",
    "      \n",
    "plt.legend() \n",
    "plt.axis([0, 60, -2, 15])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HR6DocqGZZg0"
   },
   "source": [
    "You might be wondering why we didn't specify an x-coordinate vector in the two plot commands just now.\n",
    "\n",
    "e.g. plt.plot(hrf_convolved_with_stim_time_series,'rx-')\n",
    "\n",
    "We gave the y-coord values: the vector \"hrf_convolved_with_stim_time_series\" But we didn't give any x-coord values. When the plot command is given just one vector, it automatically plots the first value at x=0, the second at x=0 etc. Because the time-axis that we want in these plots starts at 0 and goes up in steps of 1, this default is fine for us here.\n",
    "\n",
    "Next, we will make a different time-series, now with a light stimulus in our time-series being presented at t=30.\n",
    "\n",
    "We'll make a new stimulus-time-series vector for it, just like we did above. Except now there are 30 zeros, then a 1, then 30 zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAigkw2FZ6Jw"
   },
   "outputs": [],
   "source": [
    "second_light_stim_time_series = np.array([0]*30 + [1] + [0]*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rc_prCvtaF7c"
   },
   "source": [
    "Because the two vectors first_light_stim_time_series and second_light_stim_time_series are the same length (they are both 61 elements long, for the 60 second scan, with an extra element for t=0 because Python starts counting from zero), we can add them together, element-by-element.\n",
    "\n",
    "This will make a new vector that has a 1 at t=10, a 1 at t=3-, and zeros everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1569335715631,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "UrRH55wTaS5J",
    "outputId": "148f99fa-7ec7-45b7-8051-e9043813a5f7"
   },
   "outputs": [],
   "source": [
    "all_lights_time_series = first_light_stim_time_series + second_light_stim_time_series\n",
    "\n",
    "print('all_lights_time_series','\\n',all_lights_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2N-bvO5ehMK"
   },
   "source": [
    "Now we can do the convolution, using the NumPy command \"convolve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-If2b1melwF"
   },
   "outputs": [],
   "source": [
    "hrf_convolved_with_all_lights_time_series = np.convolve(all_lights_time_series,hrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0D3XBdBevVM"
   },
   "source": [
    "Let's plot the result of this convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2985,
     "status": "ok",
     "timestamp": 1569335716733,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "wJOHCZ_XewXk",
    "outputId": "06bc6ca8-bdfe-49ae-838a-961b7cf6a071"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(2,1,1)  # This is just to make the plots line up prettily \n",
    "plt.stem(all_lights_time_series,label='Time-series of light stim') \n",
    "plt.legend() \n",
    "plt.axis([0, 60, 0, 1.2])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Stimulus present / absent')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(hrf_convolved_with_all_lights_time_series,'rx-', \\\n",
    "         label='Stimulus time-series convolved with HRF') \n",
    "\n",
    "plt.legend() \n",
    "plt.axis([0, 60, -2, 15])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJLOJfBYgxHs"
   },
   "source": [
    "Now let's try moving the two stimulus onsets closer together. This will show how the two HRFs add together to make the measured signal.\n",
    "\n",
    "Let's make the second flash happen at t=16, and add it to the time-series for the first flash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2945,
     "status": "ok",
     "timestamp": 1569335716734,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "jgvm4wkugzcB",
    "outputId": "735f2554-688f-4169-9261-bde2b54b2e97"
   },
   "outputs": [],
   "source": [
    "second_light_stim_time_series = np.array([0]*16 + [1] + [0]*44)\n",
    "\n",
    "# When we add the two light-stim time series together,\n",
    "# we now have two onsets: at t=10 and t=16.\n",
    "all_lights_time_series = first_light_stim_time_series + \\\n",
    "                         second_light_stim_time_series\n",
    "\n",
    "print('all_lights_time_series','\\n',all_lights_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zyj6N5ph2Wm"
   },
   "source": [
    "Let's convolve each of these time-series with the HRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWJzrjCVh5Qh"
   },
   "outputs": [],
   "source": [
    "hrf_convolved_with_all_lights_time_series = np.convolve(all_lights_time_series,hrf)\n",
    "\n",
    "hrf_from_first_light = np.convolve(first_light_stim_time_series,hrf)\n",
    "\n",
    "hrf_from_second_light = np.convolve(second_light_stim_time_series,hrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7qyA4Bih8NZ"
   },
   "source": [
    "And now let's plot all of them, stacked on top of each other using subplots, so that we can see how they align in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3357,
     "status": "ok",
     "timestamp": 1569335717184,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "Z_eRe-RBiCUk",
    "outputId": "716e6768-1a1f-447d-a51b-446384671946"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(3,1,1)  # This is just to make the plots line up prettily \n",
    "plt.stem(all_lights_time_series,label='Time-series of light stim') \n",
    "plt.legend() \n",
    "plt.axis([0, 60, 0, 1.2])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Stimulus present / absent')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(hrf_convolved_with_all_lights_time_series,'rx-', \\\n",
    "         label='Stimulus time-series convolved with HRF') \n",
    "\n",
    "plt.legend() \n",
    "plt.axis([0, 60, -2, 15])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(hrf_from_first_light,'b-',label='HRF from first flash of light')\n",
    "plt.plot(hrf_from_second_light,'m--',label='HRF from second flash of light')\n",
    "\n",
    "plt.legend() \n",
    "plt.axis([0, 60, -2, 15])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZOBRPxdmjW2"
   },
   "source": [
    "Now let's put in a third onset, so we have onsets at t=10, t=13 and t=16. Having all these trials following each other in a row is starting to look like a blocked design. When we plot the HRF that these closely-spaced trials evoke, below, notice how the individual HRFs from each trial all start to lump together into one big HRF. That's what the HRFs look like in a blocked design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoWgqTj0msX4"
   },
   "outputs": [],
   "source": [
    "# A flash of light, with onset-time t=13\n",
    "third_light_stim_time_series = np.array([0]*13 + [1] + [0]*47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIoYeLHmpt8E"
   },
   "source": [
    "Now let's combine all three stimuli together, convolve that new stimulus time course with the HRF, and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4072,
     "status": "ok",
     "timestamp": 1569335717947,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "MUMQQpxVpz2w",
    "outputId": "e1c6dc92-b7cd-4e07-e9bc-1e8be4f13ab4"
   },
   "outputs": [],
   "source": [
    "all_lights_time_series = first_light_stim_time_series + \\\n",
    "                         second_light_stim_time_series + \\\n",
    "                         third_light_stim_time_series\n",
    "\n",
    "hrf_convolved_with_all_lights_time_series = np.convolve(all_lights_time_series,hrf)\n",
    "\n",
    "hrf_from_first_light = np.convolve(first_light_stim_time_series,hrf)\n",
    "hrf_from_second_light = np.convolve(second_light_stim_time_series,hrf)\n",
    "hrf_from_third_light = np.convolve(third_light_stim_time_series,hrf)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(3,1,1)  # This is just to make the plots line up prettily \n",
    "plt.stem(all_lights_time_series,label='Time-series of light stim') \n",
    "plt.legend() \n",
    "plt.axis([0, 60, 0, 1.2])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Stimulus present / absent')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(hrf_convolved_with_all_lights_time_series,'rx-', \\\n",
    "         label='Stimulus time-series convolved with HRF') \n",
    "\n",
    "plt.legend() \n",
    "plt.axis([0, 60, -2, 20])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(hrf_from_first_light,'b-',label='HRF from first flash of light')\n",
    "plt.plot(hrf_from_second_light,'m--',label='HRF from second flash of light')\n",
    "plt.plot(hrf_from_third_light,'g-',label='HRF from third flash of light')\n",
    "\n",
    "plt.legend() \n",
    "plt.axis([0, 60, -2, 15])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hrf_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
