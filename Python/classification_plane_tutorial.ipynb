{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_plane_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6pQuq2Y70B7",
        "colab_type": "text"
      },
      "source": [
        "## Tutorial on a basic linear classifier\n",
        "\n",
        "This is a tutorial on the basic structure of using a planar decision boundary to divide a collection of data-points into two classes, by Rajeev Raizada.\n",
        "\n",
        "Please mail any comments or suggestions to: rajeev dot raizada at gmail dot com\n",
        "\n",
        "Thank you to Michael Hanke, who first converted the original Matlab into Python, when incorporating this tutorial into PyMVPA: http://www.pymvpa.org/examples/hyperplane_demo.html\n",
        "\n",
        "I have used his Python version here, with some modifications.\n",
        "\n",
        "This is a live Jupyter notebook, running on the Google Colab server (for free!). So, you can run the code, make changes to it, and see what happens. You need have a Google login (e.g. a Gmail account) in order to run the code on Google Colab. Before you run the code, Google will show a warning, telling you to check the code below, in order to make sure that it isn't trying to do anything malicious. Don't worry, it isn't! However, it's good practice to check, so please do take a look at the code below, before running it.\n",
        "\n",
        "If you want to download the notebook, in order to run it on your own computer, then you can get it here: [classification_plane_tutorial.ipynb](http://www.bcs.rochester.edu/people/raizada/Python/classification_plane_tutorial.ipynb) \n",
        "\n",
        "#### Suggested exercise: change the code, re-run it, and see what happens\n",
        "\n",
        "A good exercise is to change the coordinates of some of the input data points, and see how this affects the classifier's resulting decision boundary.\n",
        "\n",
        "This tutorial aims to be very introductory, showing how a classification task (in this case, deciding whether people are sumo wrestlers or basketball players, based on their height and weight) can be viewed as drawing a decision boundary in a feature space. It shows how to plot the data, calculate the weights of a simple linear classifier, and see how the resulting classifier carves up the feature space into two categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4mDxul9-pmc",
        "colab_type": "text"
      },
      "source": [
        "First, we'll import some standard libraries that we'll need: NumPy, for doing math, and pyplot for making figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r29NdGnx-gLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "# This next line just makes the fonts bigger. Their default size is too small\n",
        "plt.rcParams.update({'font.size': 12})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE1kaHZ_-uLk",
        "colab_type": "text"
      },
      "source": [
        "### Two classes: sumo wrestlers and basketball players\n",
        "\n",
        "Let's look at a toy example: classifying people as either\n",
        "sumo wrestlers or basketball players, depending on their height and weight.\n",
        "\n",
        "Let's use height as the first dimension, and weight as the second dimension. Because we are later going to calculate weights for our classifier, we'll call the people's weight \"body-weight\", so as not to cause confusion between body-weight and classifier-weights!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wBfRap38tac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sumo_wrestlers_height =     [ 4, 2, 2, 3, 4 ]\n",
        "sumo_wrestlers_bodyweight = [ 8, 6, 2, 5, 7 ]\n",
        "\n",
        "basketball_players_height =     [ 3, 4, 5, 5, 3 ]\n",
        "basketball_players_bodyweight = [ 2, 5, 3, 7, 3 ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vwc_QoT86tv",
        "colab_type": "text"
      },
      "source": [
        "Let's plot this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgJry-ag88I5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(sumo_wrestlers_height, sumo_wrestlers_bodyweight, 'ro', label=\"Sumo wrestlers\")\n",
        "plt.plot(basketball_players_height, basketball_players_bodyweight, 'bx',label=\"Basketball players\")\n",
        "plt.xlim(1, 6)\n",
        "plt.ylim(0, 12)\n",
        "plt.xlabel('Height')\n",
        "plt.ylabel('Body weight')\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDnxIK_w98Xo",
        "colab_type": "text"
      },
      "source": [
        "Letâ€™s stack up the sumo data on top of the basketball players data, so that it's all part of one data-matrix. Later below, this will make it easier for us to fit our classifier to all of the data at once.\n",
        "\n",
        "We'll turn the height and weight lists into NumPy arrays, so that we can do math with them, and then we'll transpose them, to turn row vectors into column vectors.\n",
        "\n",
        "Then we'll use the NumPy command vstack() to stack those two column vectors vertically on top of each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hssTn7zo-zXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn the sumo data into np.arrays, instead of lists\n",
        "sumo_data = np.array([sumo_wrestlers_height, sumo_wrestlers_bodyweight])\n",
        "\n",
        "# Transpose to have each row be one person's data, using .T\n",
        "# Transposing flips the rows into columns (and vice versa)\n",
        "sumo_data = sumo_data.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjMI5g5BDMBH",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the sumo_data numbers and shape, to verify that it is indeed now a matrix, with the first column being height, the second column being weight, and each row being the height-weight info for one person.\n",
        "\n",
        "To do this, we use the print() command. Before we print out the actual matrix of numbers, we'll also print out the string 'sumo_data', so that we know which variable the numbers are coming from, and then a newline character, '\\n', so that the matrix gets printed out starting on its own new line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVGaQBH8DbYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('sumo_data','\\n',sumo_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBwROnxcD7ZY",
        "colab_type": "text"
      },
      "source": [
        "Now let's do the same for the basketball players' data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk4i3PxfD-Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basketball_data = np.array([basketball_players_height, basketball_players_bodyweight])\n",
        "\n",
        "basketball_data = basketball_data.T\n",
        "\n",
        "print('basketball_data','\\n',basketball_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-jmQO3KEV2V",
        "colab_type": "text"
      },
      "source": [
        "Now we'll stack them all together, to make all_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZinMDSZEYev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = np.vstack((sumo_data, basketball_data))\n",
        "\n",
        "print('all_data','\\n',all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3xnJWdCEyxj",
        "colab_type": "text"
      },
      "source": [
        "In order to be able to train a classifier on the input vectors, we need to know what the desired output categories are for each one.\n",
        "\n",
        "Let's set this to be +1 for sumo wrestlers, and -1 for basketball players.\n",
        "\n",
        "Our height-weight data matrix has five rows for sumo wrestlers, and then another five rows for basketball players. So, we need a desired-output column vector that has five rows of +1, and then five rows of -1.\n",
        "\n",
        "We can do this using the NumPy command ones(), which makes an array of ones with however many rows and columns we pass in as inputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cOu_oj1FMkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's make an array of 1s, with five rows and one column\n",
        "sumo_desired_output = np.ones((5,1))\n",
        "\n",
        "# For the column vector of -1s, we simply pre-multiply by -1\n",
        "basketball_desired_output = -1 * np.ones((5,1))\n",
        "\n",
        "# Now we stack them together\n",
        "all_desired_output = np.vstack([sumo_desired_output,basketball_desired_output])\n",
        "\n",
        "# Let's look at our vector, to check that it has the right shape.\n",
        "# Note that the ones get printed as '1.'\n",
        "# That means that the 1 is being represented as a floating-point number,\n",
        "# meaning that we can do math with it using decimal places.\n",
        "print(all_desired_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPJDnThtErEy",
        "colab_type": "text"
      },
      "source": [
        "We want to find a linear decision boundary, i.e. simply a straight line, such that all the data points on one side of the line get classified as sumo wrestlers, i.e. get mapped onto the desired output of +1, and all the data points on the other side get classified as basketball players, i.e. get mapped onto the desired output of -1.\n",
        "\n",
        "The equation for a straight line has this form:\n",
        "\n",
        "weight_vector * data_coords  -  offset_from_origin = 0\n",
        "\n",
        "We're not so interested for now in the offset_from_origin term, so we can get rid of that by subtracting the mean from our data, so that it is all centered around the origin.\n",
        "\n",
        "The means that we want to subtract are the mean-height, i.e. the mean of the first column, and the mean-weight, which is the mean of the second column. \n",
        "\n",
        "In Python, we start counting at zero, so the columns are the 0th axis. So, we can subtract the column-means from the data like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8-klgxnHmxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero_meaned_data = all_data - all_data.mean(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2LwNpbLIYiu",
        "colab_type": "text"
      },
      "source": [
        "Now, having gotten rid of that annoying offset_from_origin term, we want to find a weight vector which gives us the best solution that we can find to this equation:\n",
        "\n",
        "zero_meaned_data * weights = all_desired_output\n",
        "\n",
        "However, there is no such perfect set of weights that will yield exactly all_desired_output as the output. We can only get a best fit, such that:\n",
        "\n",
        "zero_meaned_data * weights = all_desired_output + error\n",
        "\n",
        "where the error term is as small as possible.\n",
        "\n",
        "Note that our equation:\n",
        "\n",
        "zero_meaned_data * weights = all_desired_output\n",
        "\n",
        "has exactly the same form as the equation\n",
        "from the tutorial code in [design_matrix_tutorial.ipynb](https://colab.research.google.com/drive/1JxT6UsrLRbKsY-QG-1w--lUUE3UD26PK#sandboxMode=true)\n",
        "\n",
        "which is:\n",
        "\n",
        "Design matrix * sensitivity vector = Voxel response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_pHh3coJOS0",
        "colab_type": "text"
      },
      "source": [
        "## Computing the classifier's weights\n",
        "\n",
        "The way we solve the equation is exactly the same, too. If we could find a matrix-inverse of the data matrix, then we could pre-multiply both sides by that inverse, and that would give us the weights:\n",
        "\n",
        "inv(zero_meaned_data) * zero_meaned_data * weights = inv(zero_meaned_data) * all_desired_output\n",
        "\n",
        "\n",
        "The inv(zero_meaned_data) and zero_meaned_data terms on the left would cancel each other out, and we would be left with:\n",
        "\n",
        "weights = inv(zero_meaned_data) * all_desired_output\n",
        "\n",
        "However, unfortunately there will in general not exist any matrix-inverse of the data matrix zero_meaned_data.\n",
        "Only square matrices have inverses, and not even all of them do. Luckily, however, we can use something that plays a similar role, called a pseudo-inverse. In NumPy, this is given by the command pinv.\n",
        "\n",
        "The pseudo-inverse won't give us a perfect solution to the equation\n",
        "\n",
        "zero_meaned_data * weights = all_desired_output\n",
        "\n",
        "but it will give us the best approximate solution, which is what we want.\n",
        "\n",
        "So, instead of\n",
        "\n",
        "weights = inv(zero_meaned_data) * all_desired_output\n",
        "\n",
        "we have this equation:\n",
        "\n",
        "weights = pinv(zero_meaned_data) * all_desired_output\n",
        "\n",
        "If we type np.linalg.pinv instead of pinv, so that we tell Python that the pinv function is part of NumPy's linear algebra library, then we can literally execute that equation as the command to give us our best-fit weights. One small detail is the Python symbol for matrix-multiplication is @, rather than *.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIgDNd8DJ6ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = np.linalg.pinv(zero_meaned_data) @ all_desired_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rUzIqBaLJuX",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look at this weight-vector. \n",
        "\n",
        "It has two elements: the first is the weight which gets used to multiply the first dimension (height), and the second is the weight that multiplies the second dimension (body-weight).\n",
        "\n",
        "You see now why we added body- to body-weight. Otherwise we'd be saying that the second element of weights gets used to multiply the weights, which would be confusing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8BWbfyMM4ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('weights','\\n',weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb5QR6l6NABL",
        "colab_type": "text"
      },
      "source": [
        "Note that the first weight is negative. Recall that this corresponds to the height-dimension, and that sumo wrestlers got given the class-label +1.\n",
        "\n",
        "So, a negative weight on the height dimension means that the more height you have, the **less** likely you are to be a sumo wrestler. And that makes sense, because sumo wrestlers tend to be less tall than basketball players.\n",
        "\n",
        "Similarly, the second weight is positive. This corresponds to the body-weight dimension, so its positive value means that the more weight you have, the **more** likely you are to be a sumo wrestler. Again, that makes sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L24ntmF17Lnt",
        "colab_type": "text"
      },
      "source": [
        "## Seeing how well the classifier performs\n",
        "\n",
        "Ok, let's see whether the classifier actually puts these data points into the correct categories. \n",
        "\n",
        "Note that if we were actually trying to do a real classification task, then we would split the data into training and test sets. This is just a toy example, so we're not going to do that here: we'll simply see how well the classifier performs on all the data, after having been trianed on all of that same data. In real life, this would not be a useful thing to do!\n",
        "\n",
        "That aside, let's go ahead anyway. First, let's look at the raw weighted output, before it gets thresholded into two distinct classes. To do this, we simply matrix-multiply the zero-meaned data by our freshly calculated weights. Recall that this uses the @ sign in Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "298YGze971rQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weighted_output = zero_meaned_data @ weights\n",
        "\n",
        "print('weighted_output','\\n',weighted_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjy83hZr8oDY",
        "colab_type": "text"
      },
      "source": [
        "We can see right away that the first five weighted outputs, which correspond to the sumo wrestlers and which are meant to get mapped to +1, are all positive. So, even though they don't get mapped to that exact desired-output, they do end up on the correct side of zero.\n",
        "\n",
        "Similarly, the next five weighted outputs are all meant to get mapped to -1, for basketball players, and they are all negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQuqdXC4Oncn",
        "colab_type": "text"
      },
      "source": [
        "To threshold the weighted output, so as to yield the output category-decision, we map to +1 if the weighted output is greater than 0, and -1 if it is less than zero.\n",
        "\n",
        "The easiest way to map positive numbers to +1\n",
        "and negative numbers to -1 is by first mapping them to 1 and 0 by the inequality-test\n",
        "\n",
        "(weighted_output_Z>0)\n",
        "\n",
        "and then turning 1 and 0 into +1 and -1\n",
        "\n",
        "by multipling by 2 and subtracting 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc9hLwN29RTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decision_output = 2*(weighted_output>0) - 1\n",
        "\n",
        "print('decision_output','\\n',decision_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mOnZqd39ee-",
        "colab_type": "text"
      },
      "source": [
        "This confirms that we have 1s and -1s in all the desired places. To turn this into a percentage-correct score, we can assign a 1 to every correct output, a zero to every incorrect output, and calculate the average. Note that we use a double-equals sign, ==, to test if two things are equal to each other or not. A single equals sign, in contrast, assigns the value of the thing to the right of the equals sign to the variable on the left hand side of the equals sign. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhfiYDU69lQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_is_correct = (decision_output == all_desired_output)\n",
        "num_correct = sum(output_is_correct)\n",
        "\n",
        "percentage_correct = 100 * num_correct/len(decision_output)\n",
        "\n",
        "print('The classifier got', percentage_correct[0], 'percent correct on the training set')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpoqxixaNvdt",
        "colab_type": "text"
      },
      "source": [
        "## Visualising how the classifier carves up the input space\n",
        "\n",
        "Let's have a look at how these weights carve up the input space.\n",
        "\n",
        "A useful Python command for making grids of points\n",
        "which span a particular 2D space is called \"meshgrid\". We'll make a vector of coordinates going from -7 to 7, split up into 100 pieces, and we'll make a meshgrid out of that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKzfg3yWOCac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coords_vec = np.linspace(-7, 7, 100)\n",
        "\n",
        "input_space_X, input_space_Y = np.meshgrid(coords_vec, coords_vec)\n",
        "\n",
        "weighted_output_Z = input_space_X * weights[0] + input_space_Y * weights[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yG1BuKwQVdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decision_output_Z = 2*(weighted_output_Z>0) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OktWKcHQluP",
        "colab_type": "text"
      },
      "source": [
        "Let's visualise this decision output.\n",
        "\n",
        "We'll show the output surface as colour-values, using the Matplotlib command pcolor(). In order to make the colours match up nicely with the ones we originally chose for our first plot, we'll use a colormap called \"coolwarm\", which goes from blue to red. And in order to make this coloured surface not too visually obtrusive, we'll make it fairly transparent, using what is called an alpha-channel value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LHeK3mZdIqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.pcolor(input_space_X, input_space_Y, decision_output_Z,\\\n",
        "           cmap='coolwarm',alpha=0.1)\n",
        "\n",
        "plt.xlabel('De-meaned height')\n",
        "plt.ylabel('De-meaned body-weight')\n",
        "plt.title('Decision output')\n",
        "plt.xlim(-2.5, 2.5)\n",
        "plt.ylim(-4, 7);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKK5qrzSc_XV",
        "colab_type": "text"
      },
      "source": [
        "Now let's show the original data points plotted on it, too. \n",
        "\n",
        "Because we classified the zero-meaned data, we'll pull from that data array in order to get our plot points. The first five points are our sumo wrestlers, and the next five are our basketball players.\n",
        "\n",
        "Note a slight weirdness in the way Python counts: to get the first five of something, we start at zero (we already knew that), but we stop at 5, not at 4, as one might have thought. The second number means \"stop before you get to this one\". So, we access the first five entries with [0,5], and the next five with [5,10]. That may look like we are getting the 5th entry twice, but actually we aren't!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nYw3gLnTpE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.pcolor(input_space_X, input_space_Y, decision_output_Z,\\\n",
        "           cmap='coolwarm',alpha=0.1)\n",
        "\n",
        "# First we'll plot the first five data points: the sumo wrestlers\n",
        "plt.plot(zero_meaned_data[0:5,0],zero_meaned_data[0:5,1],\\\n",
        "         'ro', label=\"Sumo wrestlers\")\n",
        "\n",
        "# Next, we'll plot the next five data points: the basketball players\n",
        "plt.plot(zero_meaned_data[5:10,0],zero_meaned_data[5:10,1],\\\n",
        "         'bx', label=\"Basketball players\")\n",
        "                  \n",
        "plt.xlabel('De-meaned height')\n",
        "plt.ylabel('De-meaned body-weight')\n",
        "plt.title('Decision output, and the data points to be classified')\n",
        "plt.legend()\n",
        "\n",
        "plt.xlim(-2.5, 2.5)\n",
        "plt.ylim(-4, 7);\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}