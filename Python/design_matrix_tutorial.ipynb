{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKb5t-k_REWZ"
   },
   "source": [
    "## Tutorial on the basic structure of an fMRI design matrix, using Python.\n",
    "\n",
    "Written by Rajeev Raizada: rajeev dot raizada at gmail dot com\n",
    " \n",
    "This file follows up on a preceding one: hrf_tutorial.m\n",
    "\n",
    "Neither file assumes any prior knowledge of linear algebra.\n",
    "\n",
    "This is a live Jupyter notebook, running on the Google Colab server (for free!). So, you can run the code, make changes to it, and see what happens. A good exercise is to change the onset times of the stimuli, and see what that does to the predicted voxel responses, the design matrix, and the estimates of the voxel sensitivities.\n",
    "\n",
    "Note that this tutorial only shows the method where the design matrix assumes a specific shape to the HRF. It is also possible to estimate the HRF without making any assumptions about its shape. This is called using the Finite Impulse Response method, or FIR. This involves using a slightly more complicated design-matrix than the one we make below.\n",
    "\n",
    "First, we import the Python modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WB-S4L7-Rfj6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import pinv  # We need the linalg part for \"pinv\", below\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# This next line just makes the fonts bigger. Their default size is too small\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7gnGfk2RxkJ"
   },
   "source": [
    "First, let's make a pretend mini-hrf, just to show examples.\n",
    "This is similar in shape to the HRFs that we looked at in\n",
    "the program hrf_tutorial.m, but it doesn't have as many time-points.\n",
    " \n",
    "One reason to use a shortened HRF like this is just to save typing! But in fact, this is approximately what a real HRF would look like if you only measured from it once every four seconds.\n",
    " \n",
    "In fMRI, the time it takes to make a whole-brain measurement is called the TR (Time for Repetition, although people say \"Repetition Time\"). \n",
    "\n",
    "So, this HRF is similar to what we'd measure if our scanner had a TR of 4 seconds. These days, fast scanners can usually manage to get a whole-brain full of data in only 2s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzUpwX39R9J9"
   },
   "outputs": [],
   "source": [
    "hrf_small = np.array([0,  4,  2,  -1,  0 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fC7Y-VbR_mx"
   },
   "source": [
    "Let's plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XSz-wVNpSAtx"
   },
   "outputs": [],
   "source": [
    "time_vec = range(0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ5DKcjlSMpx"
   },
   "source": [
    "Plot HRF against a time-vector [0,1,2,3,4]\n",
    "\n",
    "'o-' means \"use a line with circles on it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1569332508684,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "McfNWEs0SeW9",
    "outputId": "8089d1ab-6919-4494-dd77-8de1c347387e"
   },
   "outputs": [],
   "source": [
    "plt.plot(time_vec,hrf_small,'o-')  \n",
    "                            \n",
    "plt.xlabel('Time (in units of TRs, 4s long each)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.title('This is what an HRF would look like if you measure once every 4s') \n",
    "plt.grid(color='k',linestyle=':')     # Overlay a dotted-line grid on top of the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5GgENFFAVlCv"
   },
   "source": [
    "Just as we did in hrf_tutorial.m, now we're going to make\n",
    "a time-series of 1's and 0's representing the times when stimuli\n",
    "are shown. These time-series will be convolved with the HRF,\n",
    "in order to see what kinds of fMRI signals would be evoked in voxels that respond to the stimuli. These predicted responses will form the columns of our design matrix, as is shown in more detail below.\n",
    "\n",
    "Just for purposes of illustration, we're going to imagine that\n",
    "one of our stimuli is flashing up a word on the screen, and that\n",
    "the other is flashing up a picture of an object.\n",
    "\n",
    "These stimulus onsets will probably produce more complex patterns\n",
    "of neural firing than the sudden flash of light that we talked about in HST_hrf_tutorial.m, but we're going to ignore that complication for now. We'll simply suppose that each stimulus instantly kicks off its own standard-shaped HRF.\n",
    "\n",
    "This is what's typically done in event-related fMRI, and it turns\n",
    "out that it usually works pretty well.\n",
    "\n",
    "Now suppose we present a word at time t=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4r3iN9d6V09g"
   },
   "outputs": [],
   "source": [
    "word_stim_time_series = np.array([0, 1, 0, 0, 0, 0])\n",
    "stim_time_series_vec  = np.array([0, 1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aRCMCjsV8za"
   },
   "source": [
    "And let's present a picture of an object at time t=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xSTZqAmV9m0"
   },
   "outputs": [],
   "source": [
    "object_stim_time_series = np.array([0, 0, 0, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aSJtXv7Wpsp"
   },
   "source": [
    "Let's convolve these with our mini-HRF to see what kind of fMRI signals they would evoke in voxels which respond to words or pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1355,
     "status": "ok",
     "timestamp": 1569332508691,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "Pbq6IrCxWfx1",
    "outputId": "23870aa7-ec7a-45bf-96e3-c408015d36b6"
   },
   "outputs": [],
   "source": [
    "predicted_signal_that_word_would_evoke = np.convolve(word_stim_time_series,hrf_small)\n",
    "# Let's print the name of the vector, and what it looks like, with a line break\n",
    "# in between so that it looks nice\n",
    "print('predicted_signal_that_word_would_evoke','\\n',predicted_signal_that_word_would_evoke)\n",
    "\n",
    "predicted_signal_that_object_would_evoke = np.convolve(object_stim_time_series,hrf_small)\n",
    "print('predicted_signal_that_object_would_evoke','\\n',predicted_signal_that_object_would_evoke)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O5BKWK9XWwmh"
   },
   "source": [
    "Let's plot all this. We'll use subplots to make the plots line up prettily.\n",
    "\n",
    "In the subplot command below, the first number is how many rows of subplots we have: 3\n",
    "                \n",
    "The second number is how many columns: 1\n",
    "\n",
    "The third number is which subplot to draw in: the first one. \n",
    "                \n",
    "So, we end up with three plots stacked on top of each other, and we draw in the first one (which is the uppermost subplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2168,
     "status": "ok",
     "timestamp": 1569332509520,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "63CpI2rAWxTi",
    "outputId": "337c101e-5ada-4fca-b8e9-039030d674a1"
   },
   "outputs": [],
   "source": [
    "# We need a time-series vector to use as our x-coords in plot\n",
    "vec_length = predicted_signal_that_object_would_evoke.shape[0]\n",
    "time_series_vec = range(0,vec_length)\n",
    "\n",
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "plt.subplot(3,1,1)  \n",
    "        \n",
    "word_blob, word_stem, word_base = plt.stem(stim_time_series_vec,word_stim_time_series)\n",
    "plt.setp(word_blob, 'markerfacecolor', 'b')\n",
    "plt.setp(word_stem, 'color', 'b')  # Stem makes a nice looking plot with lines and circles\n",
    "\n",
    "object_blob, object_stem, object_base = plt.stem(stim_time_series_vec,object_stim_time_series)\n",
    "plt.setp(object_blob, 'markerfacecolor', 'r')\n",
    "plt.setp(object_stem, 'color', 'r')\n",
    "\n",
    "plt.grid(color='k',linestyle=':') \n",
    "\n",
    "plt.plot([0,0],[0,0],'b',label='Word stim onset time')\n",
    "plt.plot([0,0],[0,0],'r',label='Object stim onset time')\n",
    "plt.axis([0, 10, 0, 1.5]) # This just sets the display graph axis size\n",
    "                          # The first two numbers are the x-axis range: 0 10\n",
    "                          # The last two numbers are the y-axis range: 0 to 1.5\n",
    "\n",
    "plt.legend()             \n",
    "plt.ylabel('Stimulus present / absent')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(predicted_signal_that_word_would_evoke,'b*-',\\\n",
    "         label='Word-sensitive voxel would give this fMRI signal')  \n",
    "                                    \n",
    "plt.grid(color='k',linestyle=':')\n",
    "plt.legend()\n",
    "plt.axis([0, 10, -1.5, 9])\n",
    "plt.ylabel('fMRI signal')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(time_series_vec,predicted_signal_that_object_would_evoke,'r^-',\\\n",
    "         label='Object-sensitive voxel would give this fMRI signal') \n",
    "                                  \n",
    "plt.legend()\n",
    "plt.axis([0, 10, -1.5, 9])\n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwo-_YQVaXeu"
   },
   "source": [
    "## What the design matrix has in it\n",
    "\n",
    "Here's the key part. The design matrix is built up out of these predicted responses.\n",
    "\n",
    "Each column of the design matrix is the predicted fMRI signal that a voxel would give, if it were perfectly and exclusively sensitive to a particular stimulus-condition.\n",
    "\n",
    "In our case, the first column of the design matrix\n",
    "would be the vector \"predicted_signal_that_word_would_evoke\"\n",
    "that we made just above, and the second column would be the vector \"predicted_signal_that_object_would_evoke\"\n",
    "\n",
    "So, the most important part of the design matrix \n",
    "is simply these two vectors side-by-side.\n",
    "\n",
    "A real design matrix would have some other columns in it too, which have other types of predicted fMRI signals in them, e.g. what the signal would look like if the scanner's output were slowly drifting in time.\n",
    "\n",
    "But those other columns don't deal with the signal that the stimuli would be predicted to evoke in the brain, and so we can ignore them for now.\n",
    "\n",
    "It's the **columns** of the design matrix that get built up out of these predicted responses to the different stimulus types, but the actual vectors that we made above are row vectors, i.e. just a bunch of numbers in a row.\n",
    "\n",
    "So, to match the format of the design matrix, we need to turn these into column vectors, by transposing them (i.e. flipping them).\n",
    "\n",
    "We do this by putting reshape(-1,1) at the end of the vector. This (-1,1) is a bit confusing, to me at least. The -1 part means \"this can take any value\".\n",
    "So, (-1,1) means \"reshape to any number of rows, and one column\". In other words, reshape into a column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2148,
     "status": "ok",
     "timestamp": 1569332509523,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "RMh3h_FObMZt",
    "outputId": "907db957-086c-46c8-bfe7-20706631b8e0"
   },
   "outputs": [],
   "source": [
    "predicted_word_response_column_vec = predicted_signal_that_word_would_evoke.reshape(-1,1)\n",
    "print('predicted_word_response_column_vec','\\n',predicted_word_response_column_vec)\n",
    "\n",
    "print('\\n')  # Just print an empty line, to make the text output spacing look nice\n",
    "\n",
    "predicted_object_response_column_vec = predicted_signal_that_object_would_evoke.reshape(-1,1)\n",
    "print('predicted_object_response_column_vec','\\n',predicted_object_response_column_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dbir57-ueNdT"
   },
   "source": [
    "Now we can join these two column vectors together \n",
    "to make the design matrix. We simply put the two columns side-by-side.\n",
    "\n",
    "In Python, you make new matrices and vectors by \n",
    "using the commands hstack and vstack. Note that to join them together in this way, they must be the same length as each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2133,
     "status": "ok",
     "timestamp": 1569332509524,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "AjkOaehgeRAT",
    "outputId": "f735b157-ec3d-4f1c-ecbc-3d716d4f27bb"
   },
   "outputs": [],
   "source": [
    "design_matrix = np.hstack([ predicted_word_response_column_vec, predicted_object_response_column_vec ])\n",
    "\n",
    "print('design_matrix','\\n',design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ny2pg4qUestH"
   },
   "source": [
    "## Translation guide\n",
    "\n",
    "In equations, the design matrix is almost always called X\n",
    "\n",
    "Note that this is a capital \"X\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2118,
     "status": "ok",
     "timestamp": 1569332509525,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "gJDx2gUHe1d1",
    "outputId": "0c7688ee-474a-465f-ef76-d97f34e2a6fa"
   },
   "outputs": [],
   "source": [
    "X = design_matrix\n",
    "\n",
    "print('X','\\n',X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVP_lLZKe3Gf"
   },
   "source": [
    "Capitals are typically used for matrices, and small-case is used for vectors. The only difference between a vector and a matrix is that\n",
    "a vector is just a bunch of numbers in a row (a row-vector) or a bunch of numbers in a column (a column-vector), whereas a matrix is bunch of vectors stacked up next to each other to make a rectangular plt.grid, with rows **and** columns of numbers.\n",
    "\n",
    "Now let's view a grayscale plot of the design matrix, in the way that an fMRI-analysis package, such as SPM, would show it.\n",
    "\n",
    "To do this, we use the Python command \"imshow\".\n",
    "This takes each number in the design matrix and represents it as a colour, with the colour depending on how big the number is. In this case, we'll be using a gray colour-scale, so low numbers\n",
    "will be shown as darker grays, and high numbers are lighter grays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2279,
     "status": "ok",
     "timestamp": 1569332509704,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "ur0sQGbTfGh-",
    "outputId": "4bae5b85-ac9f-496f-a732-c09132f10c92"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.imshow(design_matrix, cmap='gray',interpolation='nearest')  \n",
    "      \n",
    "plt.title('Gray-scale view of design matrix')\n",
    "plt.xlabel('Each column represents one stimulus condition')\n",
    "plt.ylabel('Each row represents one point in time, one row per TR (every 4secs)')\n",
    "\n",
    "plt.colorbar()  # Shows how the numbers lie on the colour scale\n",
    "                # Note that the highest number in the design matrix,\n",
    "                # which is 4, is shown as white, and the lowest, -1,\n",
    "                # gets shown as black."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOy9SfQwzU26"
   },
   "source": [
    "Now suppose we have a voxel which responds only to words, not to objects. We can calculate how it would be predicted to respond to our word+object display as follows:\n",
    "\n",
    "Predicted response from word-sensitive voxel = \n",
    "1 * Response which word-presentation would evoke \n",
    "+ 0 * Response which object-presentation would evoke \n",
    "\n",
    "Note that this is how the voxel would be predicted to respond if there were no noise whatsoever in the system. Clearly a real fMRI signal would never be this clean.\n",
    "\n",
    "Now, let's make a \"sensitivity vector\" for this voxel, in which each entry will say how sensitive that voxel is to the corresponding stimulus condition.\n",
    "\n",
    "This voxel is sensitive to words, which are our **first** stimulus-type. And we made the predicted word response into the first column of \n",
    "the design matrix. So, the sensitivity of this voxel to words will be the first element\n",
    "in the sensitivity-vector.\n",
    "\n",
    "Similarly, the sensitivity of this voxel to the second stimulus-type, which are objects, will be the second element in the sensitivity vector.\n",
    "\n",
    "So, the sensitivity vector for a voxel with \n",
    "sensitivity = 1   to the first stimulus-type, which are words and  sensitivity = 0   to the second stimulus-type, which are objects will be [  1,  0  ]\n",
    "\n",
    "I know this seems trivial !!\n",
    "Things will get more interesting in a minute..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2456,
     "status": "ok",
     "timestamp": 1569332509904,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "CubtbRJJzlvT",
    "outputId": "f3d10807-a0e2-4ac2-eed2-7d6072b4f974"
   },
   "outputs": [],
   "source": [
    "sensitivity_vec = np.array([ 1, 0]).reshape(-1,1)\n",
    "print('sensitivity_vec','\\n',sensitivity_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnyJNZ-D1XXY"
   },
   "source": [
    "Translation guide:\n",
    "\n",
    "In equations, the numbers in the sensitivity-vector are typically called \"beta-values\", or sometimes \"beta-coefficients\" or \"beta-weights\".\n",
    "The columns of the design matrix are called \"regressors\" and the value that is assigned to each regressor is the beta-value.\n",
    "\n",
    "Note that in the example above, we are pretending that we already **know** how sensitive our voxel is to the various stimuli, but in the real world\n",
    "we don't know this. We're trying to figure out what stimuli our voxel is sensitive to, using the fMRI data that we collect in the scanner.\n",
    "This will be described more below.\n",
    "\n",
    "In math-speak, that means that we are trying to **estimate** the betas. When people want to distinguish between the true beta-value\n",
    "(which we don't know) and the estimated beta-value that we figure out from our data, then they call the true one beta and  the estimated one \"beta hat\" (beta with a circumflex sign on top of it:  ^ )\n",
    "\n",
    "( End of that part of the translation guide, back to the main theme... )\n",
    "\n",
    "So, we can now express our predicted voxel response in termsof entries in the sensitivity vector multiplied by columns in the design matrix:\n",
    "\n",
    "Predicted response from word-sensitive voxel = \\\n",
    "1 * Response which word-presentation would evoke + \\\n",
    "0 * Response which object-presentation would evoke \n",
    "\n",
    "And because of the way we made our sensitivity vector and design matrix, this can be re-written as:\n",
    "\n",
    "Predicted response from word-sensitive voxel = \\\n",
    "(First element in sensitivity vector) * (First column in design matrix) + \\\n",
    "(Second element in sensitivity vector) * (Second column in design matrix)\n",
    "\n",
    "Here's an important bit:\n",
    "The process above, of going through the elements in a vector, multiplying each element by the corresponding column in a matrix, and then adding up the results of the multiplication, is precisely what matrix multiplication does.\n",
    "\n",
    "In order to matrix-multiply our design matrix by our sensitivity-vector, we just use the NumPy command for matrix-multiplying arrays, which is np.dot()\n",
    "\n",
    "NumPy also can represent data as actual matrices, rather than arrays, and matrices get matrix-multiplied differently. But it turns out that using arrays is usually more convenient.\n",
    "See the section \"'array' or 'matrix'? Which should I use?\", at https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2439,
     "status": "ok",
     "timestamp": 1569332509906,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "9DN6nk_w1Y0v",
    "outputId": "b27e819d-9678-4688-9063-84a8e22f824a"
   },
   "outputs": [],
   "source": [
    "predicted_word_selective_voxel_response = np.dot(design_matrix,sensitivity_vec)\n",
    "print('predicted_word_selective_voxel_response','\\n',predicted_word_selective_voxel_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrqR5-T31swG"
   },
   "source": [
    "When we multiply the design matrix by the sensitivity vector, we make the i-th row of the result by taking the i-th row of the matrix, rotating it 90 degrees, multiplying it element-by-element with the sensitivity vector, and then adding that all up.\n",
    "\n",
    "Since the sensitivity vector is in this case [ 1, 0 ], multiplying each matrix row by it element-by-element means that we end up getting \\\n",
    "1* the first element in each row, and \\\n",
    "0* the second element in each row.\n",
    "\n",
    "So, by the time we have gone through all the rows, we have \\\n",
    "1* the first column of the design matrix, plus \\\n",
    "0* the second column,\n",
    "which is what we wanted.\n",
    "\n",
    "Let's plot all this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3022,
     "status": "ok",
     "timestamp": 1569332510503,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "xEZDHEWv1t5C",
    "outputId": "f5ced7d1-9048-4ac3-f4d4-e1077ed3852f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(predicted_word_response_column_vec,'b*-',label='Word-response column vector') \n",
    "plt.plot(predicted_object_response_column_vec,'r^-',label='Object-response column vector')\n",
    "plt.grid(color='k',linestyle=':') # Add a dotted grid. 'k' means colour black\n",
    "plt.legend()\n",
    "plt.axis([0, 10, -1.5, 7])\n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)')\n",
    "plt.ylabel('fMRI signal')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(predicted_word_selective_voxel_response,'ms-', \\\n",
    "         label='Word-selective voxel-response: 1*word-response + 0*object-response')\n",
    "plt.legend() \n",
    "plt.axis([0, 10, -1.5, 7]) \n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)') \n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgxggeIv3lLj"
   },
   "source": [
    "Now let's try a voxel which responds equally to both words and objects\n",
    "So, it's sensitivity vector will be [ 1, 1 ]\n",
    "\n",
    "This means that its response will be: \\\n",
    "1* the first column of the design matrix, plus \\\n",
    "1* the second column\n",
    "\n",
    "i.e. \\\n",
    "1* the response which the word stimulus evokes + \\\n",
    "1* the response which the object stimulus evokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3002,
     "status": "ok",
     "timestamp": 1569332510505,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "-fBg_-sf35Eu",
    "outputId": "4ba7abcc-4b2f-418f-ec4f-fcd1a8664bfe"
   },
   "outputs": [],
   "source": [
    "sensitivity_vec = np.array([ 1, 1 ]).reshape(-1,1)\n",
    "print('sensitivity_vec','\\n',sensitivity_vec)\n",
    "\n",
    "print('\\n')\n",
    "predicted_unselective_voxel_response = np.dot(design_matrix,sensitivity_vec)\n",
    "print('predicted_unselective_voxel_response','\\n',predicted_unselective_voxel_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lDjSHtA4gEN"
   },
   "source": [
    "Let's plot all this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3647,
     "status": "ok",
     "timestamp": 1569332511169,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "H-ya9fvh4iQh",
    "outputId": "689c3e0d-384b-4c8c-e7f1-4852b1722eae"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(predicted_word_response_column_vec,'b*-',label='Word-response column vector') \n",
    "plt.plot(predicted_object_response_column_vec,'r^-',label='Object-response column vector')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "plt.legend()\n",
    "plt.axis([0, 10, -1.5, 7])\n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)')\n",
    "plt.ylabel('fMRI signal')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(predicted_unselective_voxel_response,'ms-', \\\n",
    "         label='Unselective voxel-response: 1*word-response + 1*object-response')\n",
    "plt.legend() \n",
    "plt.axis([0, 10, -1.5, 7]) \n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)') \n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UDU-GQc-5P1k"
   },
   "source": [
    "Ok, I hope this isn't overkill: let's try a voxel which gives a normal response to words, but which gives a response to objects which is **twice** as strong. So, its sensitivity vector will be [ 1, 2 ].\n",
    "\n",
    "This means that its response will be: \\\n",
    "1* the first column of the design matrix, plus \\\n",
    "2* the second column\n",
    "\n",
    "i.e. \\\n",
    "1* the response which the word stimulus evokes + \\\n",
    "2* the response which the object stimulus evokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3628,
     "status": "ok",
     "timestamp": 1569332511171,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "ioH8EKlQ5QEL",
    "outputId": "5a495875-e2a4-4225-af6c-2c14e7478928"
   },
   "outputs": [],
   "source": [
    "sensitivity_vec = np.array([ 1, 2 ]).reshape(-1,1)\n",
    "print('sensitivity_vec','\\n',sensitivity_vec)\n",
    "\n",
    "print('\\n')\n",
    "predicted_object_preferring_voxel_response = np.dot(design_matrix,sensitivity_vec)\n",
    "print('predicted_object_preferring_voxel_response','\\n',predicted_object_preferring_voxel_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lf0W99Ro5qJB"
   },
   "source": [
    "Let's plot all this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1569335874613,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "g-JmRggC6BHa",
    "outputId": "d2299168-456e-4da4-ed96-5b5a89a5bf23"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(predicted_word_response_column_vec,'b*-',label='Word-response column vector') \n",
    "plt.plot(predicted_object_response_column_vec,'r^-',label='Object-response column vector')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "plt.legend()\n",
    "plt.axis([0, 10, -1.5, 7])\n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)')\n",
    "plt.ylabel('fMRI signal')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(predicted_object_preferring_voxel_response,'ms-', \\\n",
    "         label='Object-preferring voxel-response: 1*word-response + 2*object-response')\n",
    "plt.grid(color='k',linestyle=':')\n",
    "plt.legend() \n",
    "plt.axis([0, 10, -3, 11]) \n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)') \n",
    "plt.ylabel('fMRI signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utGVeuO2-XxE"
   },
   "source": [
    "So, to recap:\n",
    "\n",
    "Voxel response = Design matrix * sensitivity vector\n",
    "\n",
    "Each column of the design matrix is the response to a particular stimulus. Each row of it is a moment in time, with one row per MRI image-acquisition. So, reading down a column (through the rows), gives the response through\n",
    "time to a particular stimulus.\n",
    "\n",
    "Each element in the sensitivity vector is a measure of how much that voxel responds to the stimulus in the corresponding column of the design matrix.\n",
    "\n",
    "When we multiply the design matrix by the sensitivity vector, this produces a \n",
    "result which takes each column, which is the responses that each stimulus-type would evoke, then multiplies that column by how sensitive that voxel is to that particular stimulus, and then adds together the results of all those multiplications.\n",
    "\n",
    "But so far we've only been talking about an imaginary situation in which we already **know** which stimuli our voxel is sensitive to, and we use that knowledge to calculate how the voxel ought to respond. That's why we have been talking about **predicted** voxel responses so far.\n",
    "\n",
    "## Here's the key bit: \n",
    "\n",
    "In fMRI, we have exactly the reverse situation:\n",
    "we **measure** how the voxels respond, and we want to figure out which stimuli they must therefore have been sensitive to.\n",
    "\n",
    "i.e. \\\n",
    "Voxel response = Design matrix * sensitivity vector \n",
    "\n",
    "* Voxel response: We measure this with the scanner\n",
    "\n",
    "* Design matrix: We build this from the stimulus onset times convolved with the HRF\n",
    "\n",
    "* Sensitivity vector: We want to find this out\n",
    "\n",
    "So, we measure a voxel's response, and we know that it should be equal to (Design matrix * sensitivity vector).\n",
    "\n",
    "It won't be exactly equal to that, because the signal is noisy. We'll ignore the noise for now, but we'll come back to it soon below.\n",
    "\n",
    "What we need to do is to unpack the result of this multiplication, so that we can take (Design matrix * sensitivity vector) and pull out the part that we don't already know and that we want,\n",
    "namely the sensitivity vector.\n",
    "\n",
    "To do that, we need the concept of a **matrix inverse**.\n",
    "\n",
    "If multiplying by a matrix, M, does one thing,\n",
    "then multiplying by its inverse, inv(M), does the opposite.\n",
    "\n",
    "From above, we can measure the value of (Design matrix * sensitivity vector), because its value is the voxel response). What we need to find out\n",
    "is just the sensitivity vector on its own.\n",
    "\n",
    "So, we can achieve this by multiplying by the inverse of the design matrix\n",
    "\n",
    "inv(design matrix) * design matrix * sensitivity vector = sensitivity vector\n",
    "\n",
    "But since \\\n",
    "design matrix * sensitivity vector = voxel response,\n",
    "\n",
    "the above is the same as: \\\n",
    "inv(design matrix) * voxel response\n",
    "\n",
    "Given that we **know** the design matrix (we built it), we just need to calculate its inverse, multiply it by the voxel response, and then we will get that voxel's sensitivity vector.\n",
    "\n",
    "sensitivity vector = inv(design matrix) * voxel response\n",
    "\n",
    "And since the voxel's sensitivity vector is just a list of the responses which it gives to each of the stimuli which we presented, it therefore tells us which stimuli make that voxel light up.\n",
    "\n",
    "And that is what we wanted to find out!\n",
    "\n",
    "This is pretty much what any fMRI-analysis package does, although they often organise the results a bit differently. The \"sensitivity vector\" above is a list of numbers for a single voxel: each number describes how closely the BOLD signal time-course from that voxel matches to the corresponding column of the design matrix.\n",
    "\n",
    "In an fMRI-analysis package, instead of getting a separate \"sensitivity vector\" for each voxel, you may instead get a \"sensitivity image\" for each design matrix column, where each image is a brain-full of sensitivity values. Since these sensitivity values are called \"betas\", the brains-full of beta-values are called \"beta-images\".\n",
    "\n",
    "The value in a given voxel is the measure of how closely that voxel's BOLD time-course matches to the corresponding column of the design matrix.\n",
    "In SPM, for example, beta_001.nii is a brain-full of numbers saying how sensitive each voxel is to the 1st column in the design matrix. So, the beta-images are made up of the same numbers as we are calculating here for the \"sensitivity vector\", it's just that they're grouped into brain-sized images, rather than given one voxel at a time.\n",
    "\n",
    "Now, it turns out that what I just told you about inverses isn't really true. We don't multiply by the inverse of the design matrix. We multiply by something that is basically the same, only slightly more complicated, called the \"pseudo-inverse\". In Python, the pseudo-inverse of X is written pinv(X). We imported this function from numpy.linalg, using the command `from numpy.linalg import pinv` at the very top of this script, above.\n",
    "\n",
    "If you really want to know what a pinv is made out of: pinv(X) = inv(X'X)X'\n",
    "\n",
    "For our purposes, the difference between a matrix inverse and a pseudo-inverse isn't really important. The key point is to see that trying to figure out a voxel's sensitivity vector is the problem of trying to work out which vector would have to be multiplied by the design matrix, in order to give the voxel response vector\n",
    "which we measured with the scanner. \n",
    "\n",
    "So, the equation for figuring out a voxel's sensitivity is:\n",
    "\n",
    "Voxel response = Design matrix * sensitivity vector\n",
    "\n",
    "which means that we can calculate the sensitivity vector like this:\n",
    "\n",
    "Sensitivity vector = pinv(design matrix) * voxel response\n",
    "\n",
    "We mentioned above that there's noise in the signal. It turns out that with the noise included, the equation is:\n",
    "\n",
    "Voxel response = Design matrix * sensitivity vector  +  noise\n",
    "\n",
    "... where noise means \n",
    "\"anything in the measured signal that our design matrix can't explain\".\n",
    "\n",
    "This is a problem, because with the noise, it's no longer true that the measured voxel response is exactly equal to the design matrix multiplied by the sensitivity vector.\n",
    "\n",
    "Luckily, it turns out that this doesn't stop us from being able to **estimate** a sensitivity vector, even though the noise prevents us\n",
    "from being able to calculate exactly what the voxel's sensitivities are.\n",
    "\n",
    "It turns out that we can still use the pseudo-inverse of the design matrix, and that this gives us the best estimate of the sensitivity vector that we could get, despite the noise.\n",
    "\n",
    "So, although the noise prevents us from calculating the \"true\" sensitivity vector, it doesn't stop us from getting a good estimate:\n",
    "\n",
    "estimated sensitivity vector  =  pinv(design matrix) * voxel response\n",
    "\n",
    "## Translation guide:\n",
    "The fMRI signal that we measure from the scanner, which we call \"voxel response\" or \"measured_voxel_data\" here, is usually called \"y\" in equations.\n",
    "\n",
    "As before, the design matrix is called X, and the \n",
    "voxel sensitivities are called beta-values.\n",
    "To show that a beta-value is estimated, rather than being the real but unknown sensitivity of the voxel, a hat sign gets put on it: beta-hat\n",
    "\n",
    "So, instead of the equation that we write below:\n",
    "estimated_voxel_sensitivity = pinv(design_matrix) * measured_voxel_data\n",
    "\n",
    "... you'll see an equation that looks like this:\n",
    "\n",
    " beta = inv(X'X)X' * y\n",
    "\n",
    "or, with the hat-sign to show that beta is just an estimate:\n",
    "\n",
    "beta_hat = inv(X'X)X' * y\n",
    "\n",
    "\n",
    "Ok, let's try that with an example.\n",
    "\n",
    "Suppose we measure this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4203,
     "status": "ok",
     "timestamp": 1569332511776,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "3NOpr2bi-c3P",
    "outputId": "dbe6668b-b7ef-4c3b-9a53-ea0e6fa60fed"
   },
   "outputs": [],
   "source": [
    "measured_voxel_data = np.array([ 1, -1, 12, 8, -1, 5, -3, 1, -2, -1 ]).reshape(-1,1)\n",
    "\n",
    "print('measured_voxel_data','\\n',measured_voxel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXSEspczfg9C"
   },
   "source": [
    "This is is what often gets called \"y\".\n",
    "This measured signal is probably some kind of mixture of a response to the word stimulus and a response to the object stimulus, with random noise thrown on top.\n",
    "\n",
    "Let's plot it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1569332543007,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "hqA-dnva3zY-",
    "outputId": "e2634894-d69f-472c-b751-4fef0230f04f"
   },
   "outputs": [],
   "source": [
    "plt.plot(measured_voxel_data,'o-')     \n",
    "                  \n",
    "plt.xlabel('Time (in units of TRs, 4s long each)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.title('Measured voxel data')\n",
    "plt.grid(color='k',linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0vgfo70X-4Vw"
   },
   "source": [
    "What is the estimated sensitivity vector of this voxel ?\n",
    "\n",
    "Well, we make the pseudo-inverse of the design matrix, and matrix-multiply it by the vector of measured voxel data. The easiest way to write \"matrix multiply\" in Python is using the '@' symbol. \n",
    "\n",
    "This estimated_voxel_sensitivity is what gets called beta-hat in the math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4415,
     "status": "ok",
     "timestamp": 1569332512018,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "8gTy1X6t--gh",
    "outputId": "337d4b01-5cc0-4401-cc17-73bae150607d"
   },
   "outputs": [],
   "source": [
    "estimated_voxel_sensitivity = pinv(design_matrix) @ measured_voxel_data\n",
    "\n",
    "print('estimated_voxel_sensitivity','\\n',estimated_voxel_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoM4i3PxDifM"
   },
   "source": [
    "So, the estimate is that this voxel is around 3 times more sensitive to words than it is to objects.\n",
    "\n",
    "Now, let's make a plot of what the predicted response would be of a voxel that has a sensitivity matrix which is **exactly** our estimate, and compare it to the voxel response which we measured. They won't be exactly the same, because of the noise in the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07iaFZJkDjXA"
   },
   "outputs": [],
   "source": [
    "predicted_voxel_output = design_matrix @ estimated_voxel_sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfSa-mUSEAUm"
   },
   "source": [
    "This predicted overall voxel output is just the\n",
    "predicted response to the word, plus the predicted response to the object.\n",
    "As we saw in hrf_tutorial.m, the idea that we can calculate the overall response simply by adding up these two separate responses is what it\n",
    "means to say that we are assuming that the system is LINEAR.\n",
    "\n",
    "If we want to look at the predicted responses to the separate stimulus types, we can calculate them by separately multiplying the corresponding column of the design matrix by the corresponding element of the estimated sensitivity vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20JpeZkDEBcL"
   },
   "outputs": [],
   "source": [
    "predicted_response_to_word = predicted_word_response_column_vec * \\\n",
    "                             estimated_voxel_sensitivity[0]\n",
    "\n",
    "predicted_response_to_object = predicted_object_response_column_vec * \\\n",
    "                               estimated_voxel_sensitivity[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZUpQ_bDEV3D"
   },
   "source": [
    "Let's plot all this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1212,
     "status": "ok",
     "timestamp": 1569335901223,
     "user": {
      "displayName": "Rajeev Raizada",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDskaC7i5dvZEKPuTwZLxswfRB99ZYprEi4uLzS8A=s64",
      "userId": "05271354430057301364"
     },
     "user_tz": 240
    },
    "id": "4LNgDCTaEXUV",
    "outputId": "5ee1f174-e54e-4840-96e1-77e9526a48ab"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))   # This makes the figure bigger: 8x8\n",
    "\n",
    "plt.subplot(3,1,1) # This is just to make the plots line up prettily\n",
    "      \n",
    "word_blob, word_stem, word_base = plt.stem(stim_time_series_vec,word_stim_time_series)\n",
    "\n",
    "plt.setp(word_blob, 'markerfacecolor', 'b')\n",
    "plt.setp(word_stem, 'color', 'b')\n",
    "\n",
    "object_blob, object_stem, object_base = plt.stem(stim_time_series_vec,object_stim_time_series)\n",
    "plt.setp(object_blob, 'markerfacecolor', 'r')\n",
    "plt.setp(object_stem, 'color', 'r')\n",
    "\n",
    "plt.grid(color='k',linestyle=':')\n",
    "# Plot dummy lines to give the right colours to the legend\n",
    "plt.plot([0,0],[0,0],'b',label='Word stim onset time')\n",
    "plt.plot([0,0],[0,0],'r',label='Object stim onset time')\n",
    "plt.legend()\n",
    "plt.axis([0, 10, 0, 1.2]) # This just sets the display graph axis size\n",
    "plt.ylabel('Stimulus present / absent')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(predicted_response_to_word,'b*-',label='Predicted response to word')\n",
    "plt.plot(predicted_response_to_object,'ro-',label='Predicted response to object')\n",
    "plt.plot(predicted_voxel_output,'m-',label='Predicted total voxel response')\n",
    "                ### Note that the predicted_voxel_output is simply the sum of\n",
    "                ### predicted_response_to_word and predicted_response_to_object\n",
    "plt.grid(color='k',linestyle=':')\n",
    "plt.legend()\n",
    "plt.axis([0, 10, -5, 14])\n",
    "plt.ylabel('fMRI signal')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(measured_voxel_data,'g^-',label='Measured voxel response')\n",
    "plt.plot(predicted_voxel_output,'m-',label='Predicted voxel response')\n",
    "plt.legend()\n",
    "plt.axis([0, 10, -5, 14])\n",
    "plt.xlabel('Time (measured in TRs, i.e. one time-point every 4secs)')\n",
    "plt.ylabel('fMRI signal')\n",
    "plt.grid(color='k',linestyle=':')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiQxHL5-ApAZ"
   },
   "source": [
    "From Fig.8, we can see that the voxel-sensitivities that we estimated give a predicted overall voxel response which matches reasonably\n",
    "closely to the actual measured voxel data.\n",
    "\n",
    "But the match isn't perfect. That's because the MRI signal has noise in it. By \"noise\", we basically mean, \"any changes in the MRI signal that our design matrix can't explain\".\n",
    "\n",
    "All that our design matrix talks about is the predicted response to the word stimulus and the predicted response to the object stimulus.\n",
    "These predicted responses are made from HRFs, and so they change on a slow, HRF kind of time-scale, i.e. over several seconds.\n",
    "\n",
    "So, if there are either much more rapid changes in the fMRI signal, or much slower changes, then the design matrix won't be able to account for them.\n",
    "\n",
    "In a real design matrix, there would be extra columns that would try to account for any slower changes that there might be, e.g. slow drifts in the signal that the scanner is giving out.\n",
    "\n",
    "Sometimes it's also possible to explain away very rapid changes. For example, if we put columns in the design matrix that describe how much the subject's head moved, then it might turn out \n",
    "that some of the rapid MRI signal changes correlate closely with the amount of head-movement. This is what people are referring to \n",
    "when they talk about \"putting in motion as a regressor\".\n",
    "\n",
    "But there's always some noise that we simply can't get rid of. If there's not much left-over noise, then we can be fairly confident that the voxel-sensitivity vector that we calculated above\n",
    "is a good estimate. And if there's a lot of left over noise, then we probably won't be very confident.\n",
    "\n",
    "That's the basis of the statistical tests that\n",
    "any fMRI-analysis package starts to apply after it has used the design matrix to estimate how sensitive each voxel is to the various stimulus-types that we presented.\n",
    "\n",
    "However, those statistical tests are a topic for a different talk.\n",
    "\n",
    "For more detailed coverage of these and related topics, I recommend these very good tutorials by Matthew Brett, which also have accompanying Python code:\n",
    "http://matthew-brett.github.io/teaching/\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "design_matrix_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
